# QA Pipeline - Question Answering Modular & Paralelo

**[VersÃ£o em PortuguÃªs â†’](README_PT.md)**

Uma pipeline robusta, modular e paralela para processar e analisar respostas de mÃºltiplos modelos de Question Answering (QA) usando a plataforma Hugging Face.

## Tabela de ConteÃºdos

- [CaracterÃ­sticas](#-characteristics)
- [Arquitetura](#-architecture)
- [Fluxo de Dados](#-data-flow)
- [Modelos](#-models)
- [MÃ©tricas](#-metrics)
- [InstalaÃ§Ã£o](#-setup)
- [Uso](#-usage)
- [Exemplos](#-examples)
- [SaÃ­das](#-outputs)

---

## âœ¨ CaracterÃ­sticas

### ğŸ”„ Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INPUT DATA    â”‚â”€â”€â”€â–¶â”‚ DATA LOADING    â”‚â”€â”€â”€â–¶â”‚ MODEL SELECTION â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ CSV Shards   â”‚    â”‚ â€¢ Discovery     â”‚    â”‚ â€¢ Registry      â”‚
â”‚ â€¢ CLI Args      â”‚    â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Descriptors   â”‚
â”‚ â€¢ YAML Config   â”‚    â”‚ â€¢ Mapping       â”‚    â”‚ â€¢ Device Alloc  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PARALLEL PROCESSINGâ”‚â”€â”€â”€â–¶â”‚RESULTS AGGREGATIONâ”‚â”€â”€â”€â–¶â”‚METRICS CALCULATIONâ”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Multi-Process â”‚    â”‚ â€¢ Collection    â”‚    â”‚ â€¢ Overlap       â”‚
â”‚ â€¢ Batch Size    â”‚    â”‚ â€¢ Unification   â”‚    â”‚ â€¢ Performance   â”‚
â”‚ â€¢ HF Pipelines  â”‚    â”‚ â€¢ Annotation    â”‚    â”‚ â€¢ Consensus     â”‚
â”‚ â€¢ Error Handle  â”‚    â”‚ â€¢ Traceability   â”‚    â”‚ â€¢ Risk Analysis â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚ OUTPUT STORAGE  â”‚
                                           â”‚                 â”‚
                                           â”‚ â€¢ Timestamp Dir  â”‚
                                           â”‚ â€¢ CSV Files     â”‚
                                           â”‚ â€¢ JSON Data     â”‚
                                           â”‚ â€¢ MD Reports    â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“‹ Stage 1: Input & Configuration
**Entry Point**: `src/main.py` (CLI Interface)
- **Configuration Sources**:
  - Command-line arguments (`--shards`, `--models`, `--batch-size`)
  - YAML configuration (`config/pipeline_config.yaml`)
  - Environment variables
- **Data Sources**: CSV shards in `data/shards/` directory
- **Validation**: Schema validation and format checking

### ğŸ“‚ Stage 2: Data Loading (`src/data_loader.py`)
**Flexible Data Ingestion**:
- **Discovery**: Glob patterns for CSV file detection
- **Schema Mapping**: Auto-detect column patterns
  - `question`/`context` â†” `query`/`text`
- **Processing**: Concatenation with shard traceability
- **Output**: Unified DataFrame with `_shard` column

### ğŸ¤– Stage 3: Model Selection (`src/model_selector.py`)
**Dynamic Model Registry**:
- **Available Models**:
  - `distilbert`: `distilbert-base-cased-distilled-squad`
  - `roberta`: `deepset/roberta-base-squad2`  
  - `bert`: `bert-large-uncased-whole-word-masking-finetuned-squad`
- **Descriptors**: `{key, hf_name, device}` metadata
- **Device Allocation**: Automatic CUDA/CPU detection

### âš¡ Stage 4: Parallel Processing (`src/parallel_processor.py`)
**High-Performance Execution**:
- **Architecture**: ProcessPoolExecutor (true parallelism)
- **Isolation**: Each model in separate process (no GIL conflicts)
- **Batch Processing**: Configurable batch sizes
- **Integration**: Hugging Face `pipeline("question-answering")`
- **Error Recovery**: Fallback responses for failures
- **Output Format**: `{answer, score, start, end}` per prediction

### ğŸ”„ Stage 5: Results Aggregation (`src/pipeline_controller.py`)
**Data Unification**:
- **Collection**: Gather results from all model processes
- **Enrichment**: Add `model` and processing metadata
- **Consolidation**: Create unified DataFrame
- **Overlap Analysis**: Model comparison annotations
- **Traceability**: Shard and model lineage tracking

### ğŸ“Š Stage 6: Metrics Calculation (`src/metrics_calculator.py`)
**Comprehensive Analytics**:

**Overlap Analysis**:
- `overlap_count`: Number of identical answers per question
- `overlap_fraction`: Consensus ratio across models

**Performance Metrics**:
- Score distributions (mean, median, std, percentiles)
- Confidence intervals and error analysis
- Model-specific performance statistics

**Comparative Analysis**:
- Cross-model consensus evaluation
- Performance ranking and comparison
- Answer similarity analysis

**Risk Categorization**:
- Low/Medium/High confidence based on scores
- Uncertainty quantification
- Decision support metrics

### ğŸ’¾ Stage 7: Output Storage (`outputs/YYYYMMDD_HHMMSS/`)
**Structured Results**:
- **Primary Data**:
  - `results_consolidated.csv`: All predictions with annotations
  - `per_model_metrics.csv`: Flattened model statistics
  
- **Analytics**:
  - `metrics.json`: Complete metrics data structure
  - `metrics_summary.md`: Human-readable analysis report
  
- **Traceability**:
  - Timestamp directory organization
  - Model configuration export
  - Processing logs and error tracking

## Usage Examples

```bash
# Run on all shards with all models
python -m src.main --shards all --models all

# Run specific shards and models
python -m src.main --shards shard_001.csv shard_002.csv --models distilbert roberta

# Custom configuration
python -m src.main --shards all --models all --batch-size 16 --workers 4
```

## Installation

See `pyproject.toml` for dependencies. Use Poetry to install:

```bash
poetry install
poetry run python -m src.main --shards all --models all
```

```bash
qa-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ base_model.py           # Classe base abstrata para modelos
â”‚   â”œâ”€â”€ distilbert_model.py     # ImplementaÃ§Ã£o DistilBERT
â”‚   â”œâ”€â”€ roberta_model.py        # ImplementaÃ§Ã£o RoBERTa
â”‚   â”œâ”€â”€ data_loader.py          # Carregamento de shards CSV
â”‚   â”œâ”€â”€ pipeline_controller.py  # OrquestraÃ§Ã£o da pipeline
â”‚   â”œâ”€â”€ metrics_calculator.py   # CÃ¡lculo de mÃ©tricas
â”‚   â”œâ”€â”€ result_exporter.py      # ExportaÃ§Ã£o de resultados
â”‚   â”œâ”€â”€ logger_config.py        # ConfiguraÃ§Ã£o de logging
â”‚   â””â”€â”€ main.py                 # Ponto de entrada
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ model_config.yaml       # ConfiguraÃ§Ãµes dos modelos
â”‚   â””â”€â”€ pipeline_config.yaml    # ConfiguraÃ§Ãµes da pipeline
â”œâ”€â”€ data/
â”‚   â””â”€â”€ shards/                 # CSV shards
â”‚       â”œâ”€â”€ shard_001.csv
â”‚       â”œâ”€â”€ shard_002.csv
â”‚       â””â”€â”€ ...
â”œâ”€â”€ logs/                       # Logs da pipeline
â”œâ”€â”€ outputs/                    # Resultados e mÃ©tricas
â”œâ”€â”€ tests/
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md


outputs/
â””â”€â”€ run_20240115_143022/          # Timestamp da execuÃ§Ã£o
    â”œâ”€â”€ logs/
    â”‚   â””â”€â”€ pipeline_20240115_143022.log
    â”œâ”€â”€ results/
    â”‚   â”œâ”€â”€ aggregated_results.csv
    â”‚   â”œâ”€â”€ per_shard/
    â”‚   â”‚   â”œâ”€â”€ shard_001_results.csv
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ per_model/
    â”‚       â”œâ”€â”€ distilbert_results.csv
    â”‚       â””â”€â”€ roberta_results.csv
    â”œâ”€â”€ metrics/
    â”‚   â”œâ”€â”€ summary_report.md
    â”‚   â”œâ”€â”€ detailed_metrics.json
    â”‚   â”œâ”€â”€ visualizations/
    â”‚   â”‚   â”œâ”€â”€ scores_distribution.png
    â”‚   â”‚   â”œâ”€â”€ overlap_comparison.png
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ comparative_analysis.csv
    â””â”€â”€ config/
        â””â”€â”€ pipeline_config_used.yaml
```