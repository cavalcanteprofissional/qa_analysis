# QA Pipeline Modular - AnÃ¡lise de Question Answering

Uma pipeline robusta, modular e paralela para processar e analisar respostas de mÃºltiplos modelos de Question Answering (QA) usando a plataforma Hugging Face.

## ğŸ“‹ SumÃ¡rio

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitetura](#arquitetura)
- [Fluxo de Dados](#fluxo-de-dados)
- [Modelos DisponÃ­veis](#modelos-disponÃ­veis)
- [MÃ©tricas](#mÃ©tricas)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso](#uso)
- [Exemplos](#exemplos)
- [Estrutura de SaÃ­das](#estrutura-de-saÃ­das)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)

---

## âœ¨ CaracterÃ­sticas

- **Modular**: Arquitetura baseada em componentes independentes e reutilizÃ¡veis
- **Paralelo**: Processamento simultÃ¢neo de mÃºltiplos modelos usando `ProcessPoolExecutor`
- **FlexÃ­vel**: SeleÃ§Ã£o de shards e modelos via CLI ou arquivo YAML
- **Logging estruturado**: Rastreamento detalhado de execuÃ§Ã£o com timestamps
- **MÃ©tricas abrangentes**: AnÃ¡lise de confianÃ§a, overlap palavra-contexto, concordÃ¢ncia entre modelos
- **ExportaÃ§Ã£o multi-formato**: Resultados em CSV, JSON e Markdown
- **Testes automatizados**: Cobertura de componentes principais
- **Poetry**: Gerenciamento de dependÃªncias via Poetry

---

## ğŸ—ï¸ Arquitetura

### Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PipelineController                        â”‚
â”‚                (Orquestrador Principal)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚             â”‚             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ShardLoader  â”‚ â”‚ Model   â”‚ â”‚ Parallel      â”‚
        â”‚ (Dados)      â”‚ â”‚ Selectorâ”‚ â”‚ Processor     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚             â”‚             â”‚
                â”‚             â–¼             â”‚
                â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                â”‚      â”‚ Model        â”‚    â”‚
                â”‚      â”‚ Registry     â”‚    â”‚
                â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                â”‚                         â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ HF Pipeline       â”‚
                    â”‚ (Modelos: BERT,   â”‚
                    â”‚  DistilBERT,      â”‚
                    â”‚  RoBERTa)         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ MetricsCalculator  â”‚
                    â”‚ (AnÃ¡lise e SaÃ­das) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Detalhados

#### 1. **ShardLoader** (`src/data_loader.py`)
- Descobre e carrega shards CSV do diretÃ³rio `data/shards/`
- Suporta seleÃ§Ã£o por padrÃ£o glob, lista ou "all"
- Adiciona coluna `_shard` para rastreamento de origem
- Suporta mapeamento de colunas alternativas (`query`â†’`question`, `text`â†’`context`)

#### 2. **ModelSelector** (`src/model_selector.py`)
- Registro centralizado de modelos QA disponÃ­veis
- Descritores dinÃ¢micos contendo `key`, `class`, `hf_name`
- SeleÃ§Ã£o por nome ou "all"

#### 3. **ParallelProcessor** (`src/parallel_processor.py`)
- Executa modelos em processos paralelos separados
- Cada worker instancia um pipeline HF localmente
- Processamento em batches para eficiÃªncia
- Suporta CUDA quando disponÃ­vel

#### 4. **PipelineController** (`src/pipeline_controller.py`)
- OrquestraÃ§Ã£o centralizada do fluxo
- Carregamento de dados â†’ SeleÃ§Ã£o de modelos â†’ Processamento paralelo â†’ AgregaÃ§Ã£o â†’ MÃ©tricas
- Mapeamento automÃ¡tico de esquemas de entrada
- Salvamento de resultados consolidados

#### 5. **MetricsCalculator** (`src/metrics_calculator.py`)
- CÃ¡lculo de mÃ©tricas gerais e por-modelo
- AnotaÃ§Ã£o de overlap palavra-contexto
- CategorizaÃ§Ã£o de confianÃ§a
- GeraÃ§Ã£o de relatÃ³rios (JSON, Markdown, CSV)

#### 6. **BaseQAModel** (`src/base_model.py`)
- Classe abstrata para wrappers de modelos
- Define interface: `load_model()`, `predict()`, `get_metadata()`
- ImplementaÃ§Ãµes concretas:
  - `DistilBERTModel`: modelo leve baseado em BERT
  - `RobertaModel`: modelo mais robusto
  - `BERTModel`: BERT completo (Option A - large version)

---

## ğŸ”„ Fluxo de Dados

### Fluxo de ExecuÃ§Ã£o

```
1. Leitura de Entrada
   â”‚
   â”œâ”€ CLI: args (--shards, --models, ...)
   â”œâ”€ YAML Config (opcional): pipeline_config.yaml
   â””â”€ VariÃ¡veis de Ambiente: HF_TOKEN, etc.
   â”‚
   â–¼
2. Carregamento de Dados (ShardLoader)
   â”‚
   â”œâ”€ Descobre shards em data/shards/*.csv
   â”œâ”€ Seleciona conforme critÃ©rio (padrÃ£o/lista/all)
   â”œâ”€ Concatena em DataFrame Ãºnico
   â””â”€ Mapeia colunas (queryâ†’question, textâ†’context)
   â”‚
   â–¼
3. SeleÃ§Ã£o de Modelos (ModelSelector)
   â”‚
   â”œâ”€ ObtÃ©m lista de descritores do registry
   â”œâ”€ Filtra conforme seleÃ§Ã£o
   â””â”€ Retorna {key, class, hf_name} por modelo
   â”‚
   â–¼
4. Processamento Paralelo (ParallelProcessor)
   â”‚
   â”œâ”€ Cria ProcessPoolExecutor (N workers)
   â”œâ”€ Cada worker:
   â”‚  â”œâ”€ Recebe (hf_name, df_rows, batch_size, use_cuda)
   â”‚  â”œâ”€ Instancia pipeline HF localmente
   â”‚  â”œâ”€ Processa em batches
   â”‚  â””â”€ Retorna [{"question": ..., "context": ..., "answer": ..., "score": ...}]
   â””â”€ Aguarda conclusÃ£o de todos workers
   â”‚
   â–¼
5. AgregaÃ§Ã£o de Resultados
   â”‚
   â”œâ”€ Combina outputs de todos modelos
   â”œâ”€ Adiciona coluna "model" = key do modelo
   â””â”€ DataFrame consolidado: (question, context, answer, score, model, _shard)
   â”‚
   â–¼
6. AnotaÃ§Ã£o de MÃ©tricas (MetricsCalculator.annotate_overlap)
   â”‚
   â”œâ”€ Para cada linha:
   â”‚  â”œâ”€ Extrai palavras da resposta
   â”‚  â”œâ”€ Verifica presenÃ§a no contexto
   â”‚  â”œâ”€ Calcula overlap_count e overlap_fraction
   â””â”€ Adiciona colunas ao DataFrame
   â”‚
   â–¼
7. CÃ¡lculo de MÃ©tricas Agregadas
   â”‚
   â”œâ”€ Overall: mean(score), mean(overlap), total predictions
   â”œâ”€ Per-Model: mÃ©tricas por modelo
   â”œâ”€ Comparativa: concordÃ¢ncia, distribuiÃ§Ã£o de respostas
   â””â”€ CategÃ³rica: distribuiÃ§Ã£o de confianÃ§a
   â”‚
   â–¼
8. GeraÃ§Ã£o de SaÃ­das
   â”‚
   â”œâ”€ results_consolidated.csv: tabela com todas prediÃ§Ãµes + overlap
   â”œâ”€ metrics.json: mÃ©tricas estruturadas
   â”œâ”€ metrics_summary.md: relatÃ³rio legÃ­vel
   â”œâ”€ per_model_metrics.csv: resumo por modelo
   â””â”€ Logs: logs/qa_pipeline_TIMESTAMP.log
   â”‚
   â–¼
9. Retorno
   â””â”€ {"results_df": DataFrame, "metrics": dict, "out_dir": Path}
```

### Exemplo de TransformaÃ§Ã£o de Dados

**Entrada (data/shards/shard_001.csv):**
```csv
query,text
What is Python?,Python is a programming language
Who invented Python?,Guido van Rossum created Python
```

**ApÃ³s ShardLoader:**
```csv
question,context,_shard
What is Python?,Python is a programming language,shard_001.csv
Who invented Python?,Guido van Rossum created Python,shard_001.csv
```

**ApÃ³s ParallelProcessor (ex: DistilBERT):**
```csv
question,context,answer,score,model,_shard
What is Python?,Python is a programming language,Python,0.95,distilbert,shard_001.csv
Who invented Python?,Guido van Rossum created Python,Guido van Rossum,0.92,distilbert,shard_001.csv
```

**ApÃ³s MetricsCalculator.annotate_overlap:**
```csv
question,context,answer,score,model,_shard,overlap_count,overlap_fraction
What is Python?,Python is a programming language,Python,0.95,distilbert,shard_001.csv,1,1.0
Who invented Python?,Guido van Rossum created Python,Guido van Rossum,0.92,distilbert,shard_001.csv,2,1.0
```

---

## ğŸ¤– Modelos DisponÃ­veis

| Modelo | Checkpoint HF | Tamanho | DescriÃ§Ã£o |
|--------|---------------|--------|-----------|
| **distilbert** | `distilbert-base-cased-distilled-squad` | 268MB | VersÃ£o destilada, rÃ¡pida e leve |
| **roberta** | `deepset/roberta-base-squad2` | ~498MB | RoBERTa fine-tuned em SQuAD 2.0 |
| **bert** | `bert-large-uncased-whole-word-masking-finetuned-squad` | ~1.3GB | BERT completo, mais preciso |

**SeleÃ§Ã£o via CLI:**
```bash
# Um modelo
poetry run python -m src.main --models distilbert

# MÃºltiplos
poetry run python -m src.main --models distilbert roberta

# Todos
poetry run python -m src.main --models all
```

---

## ğŸ“Š MÃ©tricas

### MÃ©tricas por PrediÃ§Ã£o

Cada linha do `results_consolidated.csv` inclui:

| Coluna | Tipo | DescriÃ§Ã£o |
|--------|------|-----------|
| `question` | str | Pergunta de entrada |
| `context` | str | Contexto/passagem |
| `answer` | str | Resposta gerada |
| `score` | float | ConfianÃ§a do modelo [0.0, 1.0] |
| `model` | str | Nome do modelo (`distilbert`, `roberta`, `bert`) |
| `_shard` | str | Arquivo de origem |
| `overlap_count` | int | **Palavras da resposta presentes no contexto** |
| `overlap_fraction` | float | **overlap_count / total palavras na resposta** |

### MÃ©tricas Agregadas (metrics.json)

#### Overall
```json
{
  "overall": {
    "total_predictions": 300,
    "mean_score": 0.87,
    "median_score": 0.91,
    "avg_overlap_fraction": 0.64,
    "avg_overlap_count": 3.2
  }
}
```

**DescriÃ§Ã£o:**
- `total_predictions`: total de prediÃ§Ãµes (shards Ã— modelos)
- `mean_score`: confianÃ§a mÃ©dia
- `avg_overlap_fraction`: fraÃ§Ã£o mÃ©dia de palavras da resposta no contexto
- `avg_overlap_count`: nÃºmero mÃ©dio de palavras coincidentes

#### Per-Model
```json
{
  "per_model": {
    "distilbert": {
      "count": 100,
      "mean_score": 0.85,
      "median_score": 0.90,
      "avg_overlap_fraction": 0.62,
      "avg_overlap_count": 3.1
    },
    "bert": {
      "count": 100,
      "mean_score": 0.92,
      "median_score": 0.94,
      "avg_overlap_fraction": 0.68,
      "avg_overlap_count": 3.4
    }
  }
}
```

#### Comparativa
```json
{
  "comparative": {
    "avg_unique_answers": 2.1
  }
}
```

**DescriÃ§Ã£o:** nÃºmero mÃ©dio de respostas Ãºnicas por (question, context) â€” indica concordÃ¢ncia entre modelos.

#### CategÃ³rica
```json
{
  "categorical": {
    "low_risk": 234,
    "medium_risk": 45,
    "high_risk": 21
  }
}
```

**CategorizaÃ§Ã£o por ConfianÃ§a:**
- `low_risk`: score â‰¥ 0.8
- `medium_risk`: 0.5 â‰¤ score < 0.8
- `high_risk`: score < 0.5

### InterpretaÃ§Ã£o da MÃ©trica de Overlap

**Overlap Palavra-Contexto:**

Mede o grau em que a resposta estÃ¡ "ancorada" no contexto fornecido.

**Exemplos:**
```
Contexto: "Paris Ã© a capital da FranÃ§a, conhecida por monumentos histÃ³ricos."
Resposta: "Paris"
â†’ overlap_count=1, overlap_fraction=1.0 (100% das palavras da resposta estÃ£o no contexto)

Contexto: "O gato dorme na cama."
Resposta: "animal dormindo"
â†’ overlap_count=1 (apenas "dormindo" estÃ¡ no contexto, "animal" nÃ£o)
â†’ overlap_fraction=0.5 (50% das palavras estÃ£o presentes)

Contexto: "Python Ã© uma linguagem."
Resposta: "JavaScript Ã© melhor"
â†’ overlap_count=0, overlap_fraction=0.0 (nenhuma palavra matches)
```

**InterpretaÃ§Ã£o:**
- `overlap_fraction â‰ˆ 1.0`: Resposta altamente suportada pelo contexto (boa)
- `overlap_fraction â‰ˆ 0.5`: Resposta parcialmente suportada (moderado)
- `overlap_fraction â‰ˆ 0.0`: Resposta pouco ancorada no contexto (alerta)

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python â‰¥ 3.8.1
- Poetry â‰¥ 1.2

### Passos

1. **Clone o repositÃ³rio:**
```bash
git clone <seu-repo> dashboard_pln
cd dashboard_pln
```

2. **Instale as dependÃªncias via Poetry:**
```bash
poetry install
```

3. (Opcional) **Configure HuggingFace Token** para acesso a modelos privados:
```bash
# Criar arquivo .env
echo "HF_TOKEN=seu_token_aqui" > .env
```

4. **Verifique a instalaÃ§Ã£o:**
```bash
poetry run pytest -q
```

---

## ğŸ“ Uso

### Linha de Comando (CLI)

```bash
poetry run python -m src.main [opÃ§Ãµes]
```

**OpÃ§Ãµes:**

| OpÃ§Ã£o | PadrÃ£o | DescriÃ§Ã£o |
|-------|--------|-----------|
| `--shards` | `["all"]` | Shards a processar: `all`, glob (ex: `shard_0*`), ou lista |
| `--models` | `["all"]` | Modelos a usar: `distilbert`, `roberta`, `bert`, ou `all` |
| `--batch-size` | `32` | Tamanho do lote para inferÃªncia |
| `--workers` | `auto` | NÃºmero de processos paralelos |
| `--max-samples` | `None` | Limita samples para teste (ex: `200`) |
| `--output-dir` | `outputs` | DiretÃ³rio de saÃ­da |
| `--log-dir` | `logs` | DiretÃ³rio de logs |
| `--config` | `None` | Arquivo YAML de configuraÃ§Ã£o (opcional) |

---

## ğŸ’¡ Exemplos

### Exemplo 1: Rodar um Ãºnico shard com todos modelos

```bash
poetry run python -m src.main --shards shard_055.csv --models all
```

SaÃ­da:
```
2026-02-02 12:30:15 | INFO | qa_pipeline | Starting pipeline run
2026-02-02 12:30:16 | INFO | qa_pipeline | Mapping input columns: 'query'->'question', 'text'->'context'
2026-02-02 12:30:16 | INFO | qa_pipeline | CUDA available: False
2026-02-02 12:30:45 | INFO | qa_pipeline | Saved consolidated results to outputs/20260202_123045/results_consolidated.csv
2026-02-02 12:30:46 | INFO | qa_pipeline | Report saved: outputs/20260202_123045/metrics_summary.md
```

### Exemplo 2: Rodar com seleÃ§Ã£o de shards e modelo especÃ­fico

```bash
poetry run python -m src.main --shards shard_001.csv shard_002.csv --models bert --max-samples 50
```

### Exemplo 3: Rodar via arquivo YAML

**config/pipeline_config.yaml:**
```yaml
shards:
  - "shard_0*.csv"
models:
  - "distilbert"
  - "roberta"
batch_size: 16
workers: 2
max_samples: 100
output_dir: "outputs_custom"
log_dir: "logs_custom"
```

```bash
poetry run python -m src.main --config config/pipeline_config.yaml
```

### Exemplo 4: Teste rÃ¡pido com dados limitados

```bash
poetry run python -m src.main --shards shard_055.csv --models distilbert --max-samples 10 --output-dir outputs_test
```

---

## ğŸ“‚ Estrutura de SaÃ­das

### DiretÃ³rio de ExecuÃ§Ã£o

```
outputs/
â””â”€â”€ 20260202_123045/              # Timestamp: YYYYMMDD_HHMMSS
    â”œâ”€â”€ results_consolidated.csv   # Tabela completa (prediÃ§Ãµes + mÃ©tricas)
    â”œâ”€â”€ metrics.json               # MÃ©tricas estruturadas
    â”œâ”€â”€ metrics_summary.md         # RelatÃ³rio legÃ­vel
    â””â”€â”€ per_model_metrics.csv      # Resumo por modelo
```

### results_consolidated.csv

Tabela com todas prediÃ§Ãµes e colunas de overlap:

```csv
question,context,answer,score,model,_shard,overlap_count,overlap_fraction
"What is Python?","Python is a...",Python,0.95,distilbert,shard_001.csv,1,1.0
"What is Python?","Python is a...",Programming language,0.89,roberta,shard_001.csv,2,1.0
```

**Uso:** AnÃ¡lise manual, exportaÃ§Ã£o para BI, validaÃ§Ã£o detalhada

### metrics_summary.md

RelatÃ³rio formatado legÃ­vel para compartilhamento:

```markdown
# Metrics Summary

## Overall
- total_predictions: 300
- mean_score: 0.87
- avg_overlap_fraction: 0.64

## Per Model
### distilbert
- count: 100
- mean_score: 0.85
- avg_overlap_fraction: 0.62

### bert
- count: 100
- mean_score: 0.92
- avg_overlap_fraction: 0.68
```

### per_model_metrics.csv

Resumo por modelo para comparaÃ§Ã£o rÃ¡pida:

```csv
model,count,mean_score,median_score,avg_overlap_fraction,avg_overlap_count
distilbert,100,0.85,0.90,0.62,3.1
roberta,100,0.88,0.92,0.65,3.2
bert,100,0.92,0.94,0.68,3.4
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo YAML (config/pipeline_config.yaml)

```yaml
# Shards para processar
shards:
  - "all"  # ou ["shard_001.csv", "shard_002.csv"]

# Modelos para executar
models:
  - "all"  # ou ["distilbert", "bert"]

# InferÃªncia
batch_size: 32
workers: null  # Auto-detect CPU cores

# LimitaÃ§Ãµes (para teste)
max_samples: null  # null = sem limite

# DiretÃ³rios
output_dir: "outputs"
log_dir: "logs"
```

### VariÃ¡veis de Ambiente

```bash
# .env
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxx
CUDA_VISIBLE_DEVICES=0  # Especifique GPU se disponÃ­vel
PYTHONPATH=.
```

---

## ğŸ§ª Testes

### Rodar todos os testes:

```bash
poetry run pytest -q
```

### Rodar teste especÃ­fico:

```bash
poetry run pytest tests/test_model_selector.py -v
```

### Rodar apenas testes de overlap:

```bash
poetry run pytest tests/tests_metrics_overlap.py -v
```

---

## ğŸ“¦ DependÃªncias Principais

| Pacote | VersÃ£o | Uso |
|--------|--------|-----|
| pandas | â‰¥1.3 | ManipulaÃ§Ã£o de dados |
| transformers | â‰¥4.20 | Modelos HF QA |
| torch | â‰¥1.10 | Backend de ML |
| pyyaml | â‰¥5.4 | ConfiguraÃ§Ã£o |
| tqdm | â‰¥4.60 | Barras de progresso |
| huggingface-hub | â‰¥0.12 | AutenticaÃ§Ã£o HF |

---

## ğŸ“‹ Estrutura de Projeto

```
dashboard_pln/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py              # Classe abstrata
â”‚   â”œâ”€â”€ data_loader.py             # Carregador de shards
â”‚   â”œâ”€â”€ logger_config.py           # Logging
â”‚   â”œâ”€â”€ main.py                    # Entrada CLI
â”‚   â”œâ”€â”€ metrics_calculator.py      # CÃ¡lculo de mÃ©tricas
â”‚   â”œâ”€â”€ model_selector.py          # Registro de modelos
â”‚   â”œâ”€â”€ parallel_processor.py      # Processamento paralelo
â”‚   â”œâ”€â”€ pipeline_controller.py     # Orquestrador
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ distilbert_model.py    # Wrapper DistilBERT
â”‚       â”œâ”€â”€ roberta_model.py       # Wrapper RoBERTa
â”‚       â””â”€â”€ bert_model.py          # Wrapper BERT
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_loader.py
â”‚   â”œâ”€â”€ test_model_selector.py
â”‚   â””â”€â”€ tests_metrics_overlap.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ shards/                    # Arquivos CSV de entrada
â”‚       â”œâ”€â”€ shard_000.csv
â”‚       â”œâ”€â”€ shard_001.csv
â”‚       â””â”€â”€ ...
â”œâ”€â”€ config/
â”‚   â””â”€â”€ pipeline_config.yaml       # ConfiguraÃ§Ã£o YAML
â”œâ”€â”€ logs/                          # SaÃ­das de log
â”œâ”€â”€ outputs/                       # Resultados
â”œâ”€â”€ .env                           # VariÃ¡veis de ambiente
â”œâ”€â”€ pyproject.toml                 # DependÃªncias Poetry
â”œâ”€â”€ README_PT.md                   # Este arquivo
â””â”€â”€ projeto_av02_pln_lucas_cavalcante.ipynb  # Notebook de anÃ¡lise
```

---

## ğŸ› Troubleshooting

### Erro: "ModuleNotFoundError: No module named 'src'"

**SoluÃ§Ã£o:** Execute pelo Poetry:
```bash
poetry run python -m src.main ...
```

### Erro: "CUDA out of memory"

**SoluÃ§Ã£o:** Reduza batch size ou mude para CPU:
```bash
poetry run python -m src.main --batch-size 8
```

### Modelos nÃ£o sÃ£o baixados

**SoluÃ§Ã£o:** Verifique token HF:
```bash
poetry run huggingface-cli login
# ou
export HF_TOKEN=seu_token
```

### Logs muito grandes

**SoluÃ§Ã£o:** Limpe diretÃ³rio `logs/`:
```bash
rm logs/qa_pipeline_*.log
```

---

## ğŸ“ Contato & Suporte

Para dÃºvidas ou issues, abra uma issue no repositÃ³rio ou entre em contato com a equipe de desenvolvimento.

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ disponÃ­vel sob a licenÃ§a MIT. Veja `LICENSE` para detalhes.

---

**Ãšltima atualizaÃ§Ã£o:** Fevereiro 2, 2026
**VersÃ£o da Pipeline:** 2.0 (com overlap palavra-contexto)
