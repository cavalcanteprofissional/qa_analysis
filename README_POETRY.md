# QA Analysis Dashboard

A comprehensive Streamlit dashboard for Question Answering (QA) model analysis and comparison with parallel processing, disk-based caching, and full import/export support.

## ğŸš€ Features

### Core Functionality
- **ğŸ¤– Dual Model Support**: DistilBERT (fast) and RoBERTa (accurate) QA models
- **âš¡ Parallel Processing**: Simultaneous model execution with real-time progress tracking
- **ğŸ’¾ Disk-Based Caching**: Persistent caching for datasets and results
- **ğŸ“ Hybrid Data Interface**: Upload files or browse existing datasets
- **ğŸ“Š Comprehensive Visualization**: Interactive charts and detailed analysis
- **ğŸ“¦ Multi-Sheet Export**: Complete analysis packages with multiple CSV sheets
- **ğŸ“ Error Logging**: Detailed pipeline logs for debugging

### Advanced Features
- **Real-time Progress Tracking**: Live progress bars and status updates
- **Model Comparison**: Head-to-head performance analysis
- **Statistical Analysis**: Score distributions, overlap analysis, correlation studies
- **Export Management**: Browse and import existing analysis files
- **Quality Validation**: Automatic dataset validation and quality reports
- **Error Recovery**: Robust error handling with detailed logging

## ğŸ› ï¸ Installation

### Using Poetry (Recommended)

```bash
# Clone or download the project
cd qa-analysis-dashboard

# Install dependencies with Poetry
poetry install

# Activate virtual environment
poetry shell

# Start the dashboard
poetry run streamlit run streamlit_app.py
```

### Manual Installation

```bash
# Install dependencies manually
pip install streamlit pandas numpy torch transformers plotly matplotlib seaborn python-dotenv scikit-learn tqdm

# Start the dashboard
streamlit run streamlit_app.py
```

## ğŸ“‹ Project Structure

```
qa-analysis-dashboard/
â”œâ”€â”€ streamlit_app.py          # Main dashboard entry point
â”œâ”€â”€ pages/                   # Streamlit page modules
â”‚   â”œâ”€â”€ dashboard.py          # Main overview page
â”‚   â”œâ”€â”€ data_management.py     # Data upload and browsing
â”‚   â”œâ”€â”€ model_analysis.py      # Model configuration and processing
â”‚   â””â”€â”€ results_visualization.py # Results and export browser
â”œâ”€â”€ utils/                    # Utility modules
â”‚   â”œâ”€â”€ data_manager.py       # Unified data management with caching
â”‚   â”œâ”€â”€ parallel_processor.py  # Parallel model processing
â”‚   â”œâ”€â”€ import_export.py      # Import/export system
â”‚   â”œâ”€â”€ helpers.py           # Helper functions
â”‚   â””â”€â”€ metrics.py           # Analysis metrics
â”œâ”€â”€ config/                   # Configuration
â”‚   â””â”€â”€ settings.py           # Project settings
â”œâ”€â”€ models/                   # Model wrappers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py
â”‚   â”œâ”€â”€ distilbert_model.py
â”‚   â””â”€â”€ roberta_model.py
â”œâ”€â”€ data/                     # Data handling
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dataloader.py
â”œâ”€â”€ output/                   # Generated outputs
â”œâ”€â”€ cache/                    # Disk-based cache
â””â”€â”€ logs/                     # Error and processing logs
```

## ğŸ“– Usage Guide

### 1. Data Loading
- **Upload Files**: Use the "Upload Data" tab to upload CSV files
- **Browse Datasets**: Use "Browse Datasets" tab to select existing shards
- **Data Validation**: Automatic quality checks and validation reports

### 2. Model Configuration
- **Model Selection**: Choose DistilBERT, RoBERTa, or both
- **Processing Parameters**: Configure batch size, confidence thresholds
- **Hardware Detection**: Automatic GPU/CPU detection and optimization

### 3. Analysis Execution
- **Parallel Processing**: Models run simultaneously for efficiency
- **Progress Tracking**: Real-time progress bars and status updates
- **Error Handling**: Comprehensive error logging and recovery

### 4. Results Visualization
- **Summary Dashboard**: Overview metrics and performance stats
- **Model Comparison**: Side-by-side model analysis
- **Detailed Results**: Interactive tables with filtering
- **Export Browser**: Browse existing analysis files

### 5. Export Management
- **Multi-Sheet CSV**: Comprehensive analysis packages
- **Visualization Charts**: High-resolution plots and charts
- **Statistical Reports**: Detailed analysis summaries
- **Error Logs**: Complete processing logs

## ğŸ”§ Configuration

### Environment Variables
```bash
# Hugging Face Token (optional)
HF_TOKEN=your_hf_token_here

# Custom Model Paths (optional)
DISTILBERT_MODEL=path/to/distilbert
ROBERTA_MODEL=path/to/roberta
```

### Settings Configuration
The dashboard uses a hierarchical configuration system:

- **`config/settings.py`**: Main configuration file
- **Environment Variables**: Override with environment
- **Runtime Detection**: Automatic hardware detection
- **Caching Strategy**: Disk-based caching for persistence

## ğŸ“Š Data Format

### Input Dataset Format
```csv
_id,question,context,title
1,"What is the capital of France?","France is a country in Western Europe. Its capital is Paris...","France"
2,"Who wrote Romeo and Juliet?","Romeo and Juliet is a tragedy written by William Shakespeare...","Literature"
```

### Output Analysis Format
The dashboard generates comprehensive analysis packages with multiple sheets:

- **`resultados_completos_*.csv`**: Full results with both model outputs
- **`distilbert_top10_melhores_*.csv`**: Top 10 DistilBERT results
- **`roberta_top10_melhores_*.csv`**: Top 10 RoBERTa results
- **`global_top10_melhores_*.csv`**: Overall best 10 results
- **`discordancias_*.csv`**: Cases where models disagree significantly
- **`resumo_estatistico_*.csv`**: Statistical summary
- **`metadata_*.json`**: Complete analysis metadata

## ğŸ¯ Performance Metrics

### Model Performance Indicators
- **Confidence Scores**: Model prediction confidence (0.0-1.0)
- **Overlap Analysis**: Word overlap between context and answer
- **Processing Speed**: Tokens/second and examples/minute
- **Memory Usage**: GPU/CPU memory consumption
- **Error Rates**: Failed processing and error types

### Statistical Analyses
- **Score Distributions**: Histograms and density plots
- **Model Correlation**: Scatter plots comparing models
- **Performance Comparison**: Box plots and violin plots
- **Temporal Analysis**: Processing time over dataset size
- **Quality Metrics**: Data quality and validation scores

## ğŸ” Troubleshooting

### Common Issues

#### Model Loading Errors
```bash
# Check GPU availability
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# Verify model access
python -c "from transformers import pipeline; print('Models accessible')"
```

#### Memory Issues
```bash
# Reduce batch size in model configuration
# Use smaller datasets for testing
# Monitor memory usage with task manager
```

#### Import/Export Problems
```bash
# Check file permissions
ls -la output/
# Verify CSV format
python -c "import pandas as pd; print(pd.read_csv('your_file.csv').head())"
```

### Debug Mode
Enable detailed logging:
```python
# Set logging level
import logging
logging.basicConfig(level=logging.DEBUG)

# Check error logs
tail -f logs/qa_pipeline_*.log
```

## ğŸš€ Deployment

### Local Development
```bash
# Development mode with hot reload
poetry run streamlit run streamlit_app.py

# With custom port
poetry run streamlit run streamlit_app.py --server.port 8080
```

### Production Deployment
```bash
# With authentication
streamlit run streamlit_app.py --server.headless true

# Behind proxy
streamlit run streamlit_app.py --server.enableCORS false
```

### Docker Deployment
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY . .
RUN poetry install --no-dev

EXPOSE 8501
CMD ["poetry", "run", "streamlit", "run", "streamlit_app.py", "--server.headless", "true"]
```

## ğŸ§ª Testing

### Run Test Suite
```bash
# Basic functionality test
poetry run python simple_test.py

# Full pipeline test
poetry run python test_pipeline.py
```

### Test Coverage
- âœ… Import validation
- âœ… Configuration testing
- âœ… Data manager functionality
- âœ… Parallel processing
- âœ… Import/export operations
- âœ… Error handling
- âœ… Cache management

## ğŸ¤ Contributing

### Development Setup
```bash
# Clone repository
git clone <repository-url>
cd qa-analysis-dashboard

# Setup development environment
poetry install
poetry shell

# Run tests
python simple_test.py
```

### Code Style
```bash
# Format code
poetry run black .

# Sort imports
poetry run isort .

# Type checking
poetry run mypy .
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Support

For issues, questions, or contributions:
- ğŸ“§ Create an issue in the project repository
- ğŸ“§ Check the troubleshooting section
- ğŸ“– Review the comprehensive documentation
- ğŸ§ª Run the test suite for validation

## ğŸ”„ Changelog

### Version 0.1.0
- âœ… Initial Streamlit dashboard implementation
- âœ… Parallel model processing system
- âœ… Disk-based caching with persistence
- âœ… Comprehensive import/export functionality
- âœ… Real-time progress tracking
- âœ… Error logging and recovery system
- âœ… Multi-sheet analysis packages
- âœ… Interactive visualization dashboards
- âœ… Poetry-based dependency management